{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data_utils import get_train_batch, get_val_batch, get_test_batch\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Reshape, BatchNormalization, Flatten, Activation, Dropout\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import optimizers, metrics\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "def plot_image(image, shape=[64, 64, 3]):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_images(images, num_images):\n",
    "    fig = plt.figure(figsize=(24, 8))\n",
    "    for i in range(0, num_images):\n",
    "        fig.add_subplot(num_images//5, 5, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 10000\n",
    "n_val = 500\n",
    "batch1, batch2 = get_val_batch(0, n_val)\n",
    "X_val_batch = np.concatenate([batch1, batch2])\n",
    "X_val_batch = np.reshape(X_val_batch, (-1, 64, 64, 3))\n",
    "np.random.shuffle(X_val_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "initializer = keras.initializers.glorot_uniform(seed = None)\n",
    "regularizer = keras.regularizers.l2(1e-4)\n",
    "\n",
    "inputs = Input(shape=(64, 64, 3))\n",
    "X = Conv2D(128, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)(inputs)\n",
    "X = BatchNormalization(momentum = 0.9, epsilon = 0.001)(X)\n",
    "X = Conv2D(128, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)(inputs)\n",
    "X = BatchNormalization(momentum = 0.9, epsilon = 0.001)(X)\n",
    "X = MaxPooling2D(pool_size = 2, strides = 2, padding = 'same')(X)\n",
    "X = Conv2D(64, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)(X)\n",
    "X = BatchNormalization(momentum = 0.9, epsilon = 0.001)(X)\n",
    "X = Conv2D(64, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)(X)\n",
    "X = BatchNormalization(momentum = 0.9, epsilon = 0.001)(X)\n",
    "X = MaxPooling2D(pool_size = 2, strides = 2, padding = 'same')(X)\n",
    "X = Conv2D(32, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)(X)\n",
    "X = BatchNormalization(momentum = 0.9, epsilon = 0.001)(X)\n",
    "X = Conv2D(32, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)(X)\n",
    "X = BatchNormalization(momentum = 0.9, epsilon = 0.001)(X)\n",
    "X = MaxPooling2D(pool_size = 2, strides = 2, padding = 'same')(X)\n",
    "X = Conv2D(16, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)(X)\n",
    "X = BatchNormalization(momentum = 0.9, epsilon = 0.001)(X)\n",
    "X = Conv2D(16, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)(X)\n",
    "X = BatchNormalization(momentum = 0.9, epsilon = 0.001)(X)\n",
    "X = MaxPooling2D(pool_size = 2, strides = 2, padding = 'same')(X)\n",
    "X = Flatten()(X)\n",
    "encoded = Dense(units = 4*4*16, activation = 'tanh', kernel_initializer = initializer, kernel_regularizer = regularizer)(X)\n",
    "\n",
    "L1 = Reshape((4, 4, 16))\n",
    "L2 = Conv2D(16, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)\n",
    "L3 = BatchNormalization(momentum = 0.9, epsilon = 0.001)\n",
    "L4 = Conv2D(16, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)\n",
    "L5 = BatchNormalization(momentum = 0.9, epsilon = 0.001)\n",
    "L6 = UpSampling2D(size = (2,2), interpolation = 'nearest')\n",
    "L7 = Conv2D(32, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)\n",
    "L8 = BatchNormalization(momentum = 0.9, epsilon = 0.001)\n",
    "L9 = Conv2D(32, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)\n",
    "L10 = BatchNormalization(momentum = 0.9, epsilon = 0.001)\n",
    "L11 = UpSampling2D(size = (2,2), interpolation = 'nearest')\n",
    "L12 = Conv2D(64, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)\n",
    "L13 = BatchNormalization(momentum = 0.9, epsilon = 0.001)\n",
    "L14 = Conv2D(64, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)\n",
    "L15 = BatchNormalization(momentum = 0.9, epsilon = 0.001)\n",
    "L16 = UpSampling2D(size = (2,2), interpolation = 'nearest')\n",
    "L17 = Conv2D(128, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)\n",
    "L18 = BatchNormalization(momentum = 0.9, epsilon = 0.001)\n",
    "L19 = Conv2D(128, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)\n",
    "L20 = BatchNormalization(momentum = 0.9, epsilon = 0.001)\n",
    "L21 = UpSampling2D(size = (2,2), interpolation = 'nearest')\n",
    "L22 = Conv2D(3, kernel_size = (3,3), strides = 1, activation = 'relu', padding = 'same',\n",
    "                 kernel_initializer = initializer, kernel_regularizer = regularizer)\n",
    "\n",
    "X = L1(encoded)\n",
    "X = L2(X)\n",
    "X = L3(X)\n",
    "X = L4(X)\n",
    "X = L5(X)\n",
    "X = L6(X)\n",
    "X = L7(X)\n",
    "X = L8(X)\n",
    "X = L9(X)\n",
    "X = L10(X)\n",
    "X = L11(X)\n",
    "X = L12(X)\n",
    "X = L13(X)\n",
    "X = L14(X)\n",
    "X = L15(X)\n",
    "X = L16(X)\n",
    "X = L17(X)\n",
    "X = L18(X)\n",
    "X = L19(X)\n",
    "X = L20(X)\n",
    "X = L21(X)\n",
    "outputs = L22(X)\n",
    "\n",
    "# Auto-Encoder\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Encoder & Decoder\n",
    "encoder = Model(inputs, encoded)\n",
    "decoder_input = Input(shape = (4*4*16,))\n",
    "D = L1(decoder_input)\n",
    "D = L2(D)\n",
    "D = L3(D)\n",
    "D = L4(D)\n",
    "D = L5(D)\n",
    "D = L6(D)\n",
    "D = L7(D)\n",
    "D = L8(D)\n",
    "D = L9(D)\n",
    "D = L10(D)\n",
    "D = L11(D)\n",
    "D = L12(D)\n",
    "D = L13(D)\n",
    "D = L14(D)\n",
    "D = L15(D)\n",
    "D = L16(D)\n",
    "D = L17(D)\n",
    "D = L18(D)\n",
    "D = L19(D)\n",
    "D = L20(D)\n",
    "D = L21(D)\n",
    "decoded = L22(D)\n",
    "decoder = Model(decoder_input, decoded)\n",
    "\n",
    "opt = optimizers.Adam(lr = 5e-4, decay = 0.0, epsilon = 1e-8, amsgrad = False)\n",
    "model.compile(optimizer = opt, loss = 'mse', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 16)          4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 16)          64        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 4, 16)          64        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 64, 64, 3)         3459      \n",
      "=================================================================\n",
      "Total params: 516,931\n",
      "Trainable params: 515,267\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "dictionary = {v.name: i for i, v in enumerate(model.layers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data_generator(batch_size):\n",
    "    while(True):\n",
    "        batch1, batch2 = get_train_batch(batch_size)\n",
    "        X_batch = np.concatenate([batch1, batch2])\n",
    "        X_batch = np.reshape(X_batch, (-1, 64, 64, 3))\n",
    "        np.random.shuffle(X_batch)\n",
    "        yield X_batch, X_batch\n",
    "        \n",
    "def schedule(epoch, lr):\n",
    "    decay_rate = 0.5\n",
    "    decay_step = 250\n",
    "    if epoch % decay_step == 0 and epoch:\n",
    "        return lr * decay_rate\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "400/400 [==============================] - 520s 1s/step - loss: 0.1052 - mean_absolute_error: 0.0383 - val_loss: 0.0777 - val_mean_absolute_error: 0.0238\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07768, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 500s 1s/step - loss: 0.0640 - mean_absolute_error: 0.0222 - val_loss: 0.0517 - val_mean_absolute_error: 0.0205\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07768 to 0.05174, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 503s 1s/step - loss: 0.0425 - mean_absolute_error: 0.0200 - val_loss: 0.0342 - val_mean_absolute_error: 0.0192\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05174 to 0.03423, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 502s 1s/step - loss: 0.0281 - mean_absolute_error: 0.0179 - val_loss: 0.0226 - val_mean_absolute_error: 0.0166\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03423 to 0.02259, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 502s 1s/step - loss: 0.0189 - mean_absolute_error: 0.0158 - val_loss: 0.0158 - val_mean_absolute_error: 0.0146\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02259 to 0.01580, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 501s 1s/step - loss: 0.0132 - mean_absolute_error: 0.0142 - val_loss: 0.0115 - val_mean_absolute_error: 0.0133\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01580 to 0.01151, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 501s 1s/step - loss: 0.0099 - mean_absolute_error: 0.0131 - val_loss: 0.0087 - val_mean_absolute_error: 0.0122\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01151 to 0.00871, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 500s 1s/step - loss: 0.0078 - mean_absolute_error: 0.0121 - val_loss: 0.0071 - val_mean_absolute_error: 0.0116\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00871 to 0.00713, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 500s 1s/step - loss: 0.0065 - mean_absolute_error: 0.0113 - val_loss: 0.0061 - val_mean_absolute_error: 0.0108\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00713 to 0.00606, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 500s 1s/step - loss: 0.0056 - mean_absolute_error: 0.0107 - val_loss: 0.0054 - val_mean_absolute_error: 0.0106\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00606 to 0.00545, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 499s 1s/step - loss: 0.0051 - mean_absolute_error: 0.0103 - val_loss: 0.0047 - val_mean_absolute_error: 0.0097\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00545 to 0.00473, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 498s 1s/step - loss: 0.0047 - mean_absolute_error: 0.0097 - val_loss: 0.0046 - val_mean_absolute_error: 0.0098\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00473 to 0.00464, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 497s 1s/step - loss: 0.0043 - mean_absolute_error: 0.0093 - val_loss: 0.0042 - val_mean_absolute_error: 0.0092\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00464 to 0.00420, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 14/40\n",
      "400/400 [==============================] - 497s 1s/step - loss: 0.0041 - mean_absolute_error: 0.0090 - val_loss: 0.0039 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00420 to 0.00387, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 15/40\n",
      "400/400 [==============================] - 497s 1s/step - loss: 0.0038 - mean_absolute_error: 0.0087 - val_loss: 0.0069 - val_mean_absolute_error: 0.0125\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00387\n",
      "Epoch 16/40\n",
      "400/400 [==============================] - 497s 1s/step - loss: 0.0037 - mean_absolute_error: 0.0084 - val_loss: 0.0083 - val_mean_absolute_error: 0.0140\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00387\n",
      "Epoch 17/40\n",
      "400/400 [==============================] - 497s 1s/step - loss: 0.0035 - mean_absolute_error: 0.0082 - val_loss: 0.0033 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00387 to 0.00333, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 18/40\n",
      "400/400 [==============================] - 497s 1s/step - loss: 0.0033 - mean_absolute_error: 0.0078 - val_loss: 0.0033 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00333 to 0.00329, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 19/40\n",
      "400/400 [==============================] - 496s 1s/step - loss: 0.0032 - mean_absolute_error: 0.0077 - val_loss: 0.0032 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00329 to 0.00316, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 20/40\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0030 - mean_absolute_error: 0.0075 - val_loss: 0.0030 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00316 to 0.00304, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 21/40\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0030 - mean_absolute_error: 0.0073 - val_loss: 0.0030 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00304 to 0.00295, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 22/40\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0028 - mean_absolute_error: 0.0070 - val_loss: 0.0029 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00295 to 0.00289, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 23/40\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0027 - mean_absolute_error: 0.0070 - val_loss: 0.0027 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00289 to 0.00270, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 24/40\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0026 - mean_absolute_error: 0.0068 - val_loss: 0.0025 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00270 to 0.00253, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 25/40\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0025 - mean_absolute_error: 0.0066 - val_loss: 0.0025 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00253 to 0.00246, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 26/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0026 - mean_absolute_error: 0.0066 - val_loss: 0.0025 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00246\n",
      "Epoch 27/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0024 - mean_absolute_error: 0.0063 - val_loss: 0.0025 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00246 to 0.00246, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 28/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0023 - mean_absolute_error: 0.0063 - val_loss: 0.0023 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00246 to 0.00234, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 29/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0023 - mean_absolute_error: 0.0062 - val_loss: 0.0025 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00234\n",
      "Epoch 30/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0022 - mean_absolute_error: 0.0061 - val_loss: 0.0022 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00234 to 0.00216, saving model to ./models/AutoEncoder_0616_256.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0022 - mean_absolute_error: 0.0061 - val_loss: 0.0023 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00216\n",
      "Epoch 32/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0021 - mean_absolute_error: 0.0059 - val_loss: 0.0020 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00216 to 0.00203, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 33/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0021 - mean_absolute_error: 0.0058 - val_loss: 0.0020 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00203 to 0.00201, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 34/40\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0021 - mean_absolute_error: 0.0058 - val_loss: 0.0022 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00201\n",
      "Epoch 35/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0021 - mean_absolute_error: 0.0058 - val_loss: 0.0019 - val_mean_absolute_error: 0.0055\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00201 to 0.00192, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 36/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0020 - mean_absolute_error: 0.0056 - val_loss: 0.0020 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00192\n",
      "Epoch 37/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0020 - mean_absolute_error: 0.0057 - val_loss: 0.0019 - val_mean_absolute_error: 0.0055\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00192\n",
      "Epoch 38/40\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0020 - mean_absolute_error: 0.0056 - val_loss: 0.0019 - val_mean_absolute_error: 0.0055\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00192 to 0.00192, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 39/40\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0020 - mean_absolute_error: 0.0056 - val_loss: 0.0018 - val_mean_absolute_error: 0.0052\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00192 to 0.00180, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 40/40\n",
      "400/400 [==============================] - 493s 1s/step - loss: 0.0020 - mean_absolute_error: 0.0056 - val_loss: 0.0018 - val_mean_absolute_error: 0.0053\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00180\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "\n",
    "batch_size = 25\n",
    "initial_epoch = 0\n",
    "\n",
    "CP = ModelCheckpoint(filepath = './models/AutoEncoder_0616_256.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'auto')\n",
    "ES = EarlyStopping(monitor = 'val_loss', patience = 30, verbose = 1, mode = 'auto', restore_best_weights = True)\n",
    "LS = LearningRateScheduler(schedule, verbose = 1)\n",
    "\n",
    "history = model.fit_generator(batch_data_generator(batch_size), steps_per_epoch = n_train // batch_size, epochs = epochs, verbose = 1,\n",
    "                             callbacks = [ES, CP], validation_data = (X_val_batch, X_val_batch),\n",
    "                             shuffle = False, initial_epoch = initial_epoch)\n",
    "initial_epoch = epochs\n",
    "encoder.save('./models/Encoder_0616_256.hdf5')\n",
    "decoder.save('./models/Decoder_0616_256.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr = 1e-4, decay = 0.0, epsilon = 1e-8, amsgrad = False)\n",
    "model.compile(optimizer = opt, loss = 'mse', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/65\n",
      "400/400 [==============================] - 502s 1s/step - loss: 0.0014 - mean_absolute_error: 0.0043 - val_loss: 0.0013 - val_mean_absolute_error: 0.0040\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00180 to 0.00125, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 42/65\n",
      "400/400 [==============================] - 498s 1s/step - loss: 0.0013 - mean_absolute_error: 0.0041 - val_loss: 0.0012 - val_mean_absolute_error: 0.0039\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00125 to 0.00120, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 43/65\n",
      "400/400 [==============================] - 498s 1s/step - loss: 0.0012 - mean_absolute_error: 0.0041 - val_loss: 0.0012 - val_mean_absolute_error: 0.0040\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00120 to 0.00117, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 44/65\n",
      "400/400 [==============================] - 498s 1s/step - loss: 0.0012 - mean_absolute_error: 0.0041 - val_loss: 0.0011 - val_mean_absolute_error: 0.0039\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00117 to 0.00114, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 45/65\n",
      "400/400 [==============================] - 498s 1s/step - loss: 0.0012 - mean_absolute_error: 0.0040 - val_loss: 0.0011 - val_mean_absolute_error: 0.0039\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00114 to 0.00111, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 46/65\n",
      "400/400 [==============================] - 497s 1s/step - loss: 0.0012 - mean_absolute_error: 0.0040 - val_loss: 0.0011 - val_mean_absolute_error: 0.0038\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00111 to 0.00107, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 47/65\n",
      "400/400 [==============================] - 496s 1s/step - loss: 0.0011 - mean_absolute_error: 0.0040 - val_loss: 0.0012 - val_mean_absolute_error: 0.0041\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00107\n",
      "Epoch 48/65\n",
      "400/400 [==============================] - 496s 1s/step - loss: 0.0011 - mean_absolute_error: 0.0040 - val_loss: 0.0011 - val_mean_absolute_error: 0.0040\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00107\n",
      "Epoch 49/65\n",
      "400/400 [==============================] - 496s 1s/step - loss: 0.0011 - mean_absolute_error: 0.0039 - val_loss: 0.0011 - val_mean_absolute_error: 0.0039\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00107 to 0.00107, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 50/65\n",
      "400/400 [==============================] - 496s 1s/step - loss: 0.0011 - mean_absolute_error: 0.0040 - val_loss: 0.0011 - val_mean_absolute_error: 0.0039\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00107\n",
      "Epoch 51/65\n",
      "400/400 [==============================] - 496s 1s/step - loss: 0.0011 - mean_absolute_error: 0.0039 - val_loss: 0.0011 - val_mean_absolute_error: 0.0040\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00107\n",
      "Epoch 52/65\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0011 - mean_absolute_error: 0.0040 - val_loss: 0.0010 - val_mean_absolute_error: 0.0037\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00107 to 0.00102, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 53/65\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0011 - mean_absolute_error: 0.0039 - val_loss: 0.0010 - val_mean_absolute_error: 0.0038\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00102\n",
      "Epoch 54/65\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0011 - mean_absolute_error: 0.0039 - val_loss: 0.0010 - val_mean_absolute_error: 0.0038\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00102\n",
      "Epoch 55/65\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0011 - mean_absolute_error: 0.0039 - val_loss: 9.8583e-04 - val_mean_absolute_error: 0.0037\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00102 to 0.00099, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 56/65\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0010 - mean_absolute_error: 0.0039 - val_loss: 9.9953e-04 - val_mean_absolute_error: 0.0038\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00099\n",
      "Epoch 57/65\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0010 - mean_absolute_error: 0.0039 - val_loss: 9.9536e-04 - val_mean_absolute_error: 0.0037\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00099\n",
      "Epoch 58/65\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0010 - mean_absolute_error: 0.0039 - val_loss: 0.0010 - val_mean_absolute_error: 0.0038\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00099\n",
      "Epoch 59/65\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0010 - mean_absolute_error: 0.0039 - val_loss: 0.0010 - val_mean_absolute_error: 0.0039\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00099\n",
      "Epoch 60/65\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0010 - mean_absolute_error: 0.0039 - val_loss: 9.6965e-04 - val_mean_absolute_error: 0.0037\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00099 to 0.00097, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 61/65\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0010 - mean_absolute_error: 0.0039 - val_loss: 0.0010 - val_mean_absolute_error: 0.0038\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00097\n",
      "Epoch 62/65\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0010 - mean_absolute_error: 0.0038 - val_loss: 0.0010 - val_mean_absolute_error: 0.0038\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00097\n",
      "Epoch 63/65\n",
      "400/400 [==============================] - 494s 1s/step - loss: 9.9893e-04 - mean_absolute_error: 0.0038 - val_loss: 9.5933e-04 - val_mean_absolute_error: 0.0037\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00097 to 0.00096, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 64/65\n",
      "400/400 [==============================] - 495s 1s/step - loss: 0.0010 - mean_absolute_error: 0.0038 - val_loss: 9.6348e-04 - val_mean_absolute_error: 0.0037\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00096\n",
      "Epoch 65/65\n",
      "400/400 [==============================] - 494s 1s/step - loss: 0.0010 - mean_absolute_error: 0.0038 - val_loss: 0.0011 - val_mean_absolute_error: 0.0041\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00096\n"
     ]
    }
   ],
   "source": [
    "epochs = 65\n",
    "\n",
    "history = model.fit_generator(batch_data_generator(batch_size), steps_per_epoch = n_train // batch_size, epochs = epochs, verbose = 1,\n",
    "                             callbacks = [ES, CP], validation_data = (X_val_batch, X_val_batch),\n",
    "                             shuffle = False, initial_epoch = initial_epoch)\n",
    "initial_epoch = epochs\n",
    "encoder.save('./models/Encoder_0616_256.hdf5')\n",
    "decoder.save('./models/Decoder_0616_256.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr = 5e-5, decay = 0.0, epsilon = 1e-8, amsgrad = False)\n",
    "model.compile(optimizer = opt, loss = 'mse', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/85\n",
      "400/400 [==============================] - 500s 1s/step - loss: 9.1078e-04 - mean_absolute_error: 0.0036 - val_loss: 8.7429e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00096 to 0.00087, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 67/85\n",
      "400/400 [==============================] - 493s 1s/step - loss: 8.8342e-04 - mean_absolute_error: 0.0035 - val_loss: 8.5644e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00087 to 0.00086, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 68/85\n",
      "400/400 [==============================] - 493s 1s/step - loss: 8.8296e-04 - mean_absolute_error: 0.0035 - val_loss: 8.5327e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00086 to 0.00085, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 69/85\n",
      "400/400 [==============================] - 494s 1s/step - loss: 8.7940e-04 - mean_absolute_error: 0.0035 - val_loss: 8.7281e-04 - val_mean_absolute_error: 0.0035\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00085\n",
      "Epoch 70/85\n",
      "400/400 [==============================] - 493s 1s/step - loss: 8.7756e-04 - mean_absolute_error: 0.0035 - val_loss: 8.6208e-04 - val_mean_absolute_error: 0.0035\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00085\n",
      "Epoch 71/85\n",
      "400/400 [==============================] - 492s 1s/step - loss: 8.6493e-04 - mean_absolute_error: 0.0035 - val_loss: 8.3720e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00085 to 0.00084, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 72/85\n",
      "400/400 [==============================] - 495s 1s/step - loss: 8.6050e-04 - mean_absolute_error: 0.0035 - val_loss: 8.2904e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00084 to 0.00083, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 73/85\n",
      "400/400 [==============================] - 492s 1s/step - loss: 8.5445e-04 - mean_absolute_error: 0.0035 - val_loss: 8.2391e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00083 to 0.00082, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 74/85\n",
      "400/400 [==============================] - 492s 1s/step - loss: 8.5225e-04 - mean_absolute_error: 0.0035 - val_loss: 8.3918e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00082\n",
      "Epoch 75/85\n",
      "400/400 [==============================] - 492s 1s/step - loss: 8.4970e-04 - mean_absolute_error: 0.0035 - val_loss: 8.2035e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00082 to 0.00082, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 76/85\n",
      "400/400 [==============================] - 492s 1s/step - loss: 8.3714e-04 - mean_absolute_error: 0.0034 - val_loss: 8.3939e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00082\n",
      "Epoch 77/85\n",
      "400/400 [==============================] - 492s 1s/step - loss: 8.4435e-04 - mean_absolute_error: 0.0035 - val_loss: 8.4492e-04 - val_mean_absolute_error: 0.0035\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00082\n",
      "Epoch 78/85\n",
      "400/400 [==============================] - 492s 1s/step - loss: 8.3549e-04 - mean_absolute_error: 0.0034 - val_loss: 8.1593e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00082 to 0.00082, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 79/85\n",
      "400/400 [==============================] - 491s 1s/step - loss: 8.3572e-04 - mean_absolute_error: 0.0035 - val_loss: 8.2536e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00082\n",
      "Epoch 80/85\n",
      "400/400 [==============================] - 491s 1s/step - loss: 8.3173e-04 - mean_absolute_error: 0.0034 - val_loss: 8.3471e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00082\n",
      "Epoch 81/85\n",
      "400/400 [==============================] - 491s 1s/step - loss: 8.3229e-04 - mean_absolute_error: 0.0034 - val_loss: 8.2359e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00082\n",
      "Epoch 82/85\n",
      "400/400 [==============================] - 491s 1s/step - loss: 8.2392e-04 - mean_absolute_error: 0.0034 - val_loss: 8.0160e-04 - val_mean_absolute_error: 0.0033\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00082 to 0.00080, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 83/85\n",
      "400/400 [==============================] - 492s 1s/step - loss: 8.2238e-04 - mean_absolute_error: 0.0034 - val_loss: 8.2210e-04 - val_mean_absolute_error: 0.0034\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00080\n",
      "Epoch 84/85\n",
      "400/400 [==============================] - 492s 1s/step - loss: 8.2315e-04 - mean_absolute_error: 0.0034 - val_loss: 7.9252e-04 - val_mean_absolute_error: 0.0033\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00080 to 0.00079, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 85/85\n",
      "400/400 [==============================] - 493s 1s/step - loss: 8.1530e-04 - mean_absolute_error: 0.0034 - val_loss: 7.9581e-04 - val_mean_absolute_error: 0.0033\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00079\n"
     ]
    }
   ],
   "source": [
    "epochs = 85\n",
    "\n",
    "history = model.fit_generator(batch_data_generator(batch_size), steps_per_epoch = n_train // batch_size, epochs = epochs, verbose = 1,\n",
    "                             callbacks = [ES, CP], validation_data = (X_val_batch, X_val_batch),\n",
    "                             shuffle = False, initial_epoch = initial_epoch)\n",
    "initial_epoch = epochs\n",
    "encoder.save('./models/Encoder_0616_256.hdf5')\n",
    "decoder.save('./models/Decoder_0616_256.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr = 1e-5, decay = 0.0, epsilon = 1e-8, amsgrad = False)\n",
    "model.compile(optimizer = opt, loss = 'mse', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "400/400 [==============================] - 498s 1s/step - loss: 7.4385e-04 - mean_absolute_error: 0.0032 - val_loss: 7.2266e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00079 to 0.00072, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 87/100\n",
      "400/400 [==============================] - 493s 1s/step - loss: 7.3761e-04 - mean_absolute_error: 0.0032 - val_loss: 7.2009e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00072 to 0.00072, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 88/100\n",
      "400/400 [==============================] - 493s 1s/step - loss: 7.3399e-04 - mean_absolute_error: 0.0032 - val_loss: 7.2190e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00072\n",
      "Epoch 89/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.2967e-04 - mean_absolute_error: 0.0031 - val_loss: 7.1468e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00072 to 0.00071, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 90/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.2630e-04 - mean_absolute_error: 0.0031 - val_loss: 7.0897e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00071 to 0.00071, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 91/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.2345e-04 - mean_absolute_error: 0.0031 - val_loss: 7.1694e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00071\n",
      "Epoch 92/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.2421e-04 - mean_absolute_error: 0.0031 - val_loss: 7.0686e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00071 to 0.00071, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 93/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.2358e-04 - mean_absolute_error: 0.0031 - val_loss: 7.0506e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00071 to 0.00071, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 94/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.1957e-04 - mean_absolute_error: 0.0031 - val_loss: 7.0682e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00071\n",
      "Epoch 95/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.1854e-04 - mean_absolute_error: 0.0031 - val_loss: 7.0821e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00071\n",
      "Epoch 96/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.1231e-04 - mean_absolute_error: 0.0031 - val_loss: 7.0309e-04 - val_mean_absolute_error: 0.0031\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00071 to 0.00070, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 97/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.1242e-04 - mean_absolute_error: 0.0031 - val_loss: 7.0089e-04 - val_mean_absolute_error: 0.0030\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00070 to 0.00070, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 98/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.1224e-04 - mean_absolute_error: 0.0031 - val_loss: 6.9694e-04 - val_mean_absolute_error: 0.0030\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00070 to 0.00070, saving model to ./models/AutoEncoder_0616_256.hdf5\n",
      "Epoch 99/100\n",
      "400/400 [==============================] - 492s 1s/step - loss: 7.0770e-04 - mean_absolute_error: 0.0031 - val_loss: 6.9837e-04 - val_mean_absolute_error: 0.0030\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00070\n",
      "Epoch 100/100\n",
      "400/400 [==============================] - 493s 1s/step - loss: 7.0784e-04 - mean_absolute_error: 0.0031 - val_loss: 6.9452e-04 - val_mean_absolute_error: 0.0030\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00070 to 0.00069, saving model to ./models/AutoEncoder_0616_256.hdf5\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "history = model.fit_generator(batch_data_generator(batch_size), steps_per_epoch = n_train // batch_size, epochs = epochs, verbose = 1,\n",
    "                             callbacks = [ES, CP], validation_data = (X_val_batch, X_val_batch),\n",
    "                             shuffle = False, initial_epoch = initial_epoch)\n",
    "initial_epoch = epochs\n",
    "encoder.save('./models/Encoder_0616_256.hdf5')\n",
    "decoder.save('./models/Decoder_0616_256.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = model.evaluate(X_val_batch, X_val_batch, batch_size = 32, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check with Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1, batch2 = get_train_batch(1)\n",
    "X_batch = np.concatenate([batch1, batch2])\n",
    "X_batch = np.reshape(X_batch, (-1, 64, 64, 3))\n",
    "outputs = model.predict_on_batch(X_batch)\n",
    "plot_image(X_batch[10])\n",
    "plot_image(outputs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check with Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1, batch2 = get_val_batch(0, 1)\n",
    "X_batch = np.concatenate([batch1, batch2])\n",
    "X_batch = np.reshape(X_batch, (-1, 64, 64, 3))\n",
    "outputs = model.predict_on_batch(X_batch)\n",
    "plot_images(X_batch, 20)\n",
    "plot_images(outputs, 20)\n",
    "plot_image(X_batch[5])\n",
    "plot_image(outputs[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if encoder & decoder work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch1, batch2 = get_train_batch(1)\n",
    "X_batch = np.concatenate([batch1, batch2])\n",
    "X_batch = np.reshape(X_batch, (-1, 64, 64, 3))\n",
    "encoded_imgs = encoder.predict_on_batch(X_batch)\n",
    "decoded_imgs = decoder.predict_on_batch(encoded_imgs)\n",
    "plot_image(X_batch[6])\n",
    "plot_image(decoded_imgs[6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
